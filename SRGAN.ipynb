{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v_IxJfmDezm",
        "outputId": "75e802c1-b1d6-4b63-c5af-bd1a0493be74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.3.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# ─── 1. Install Dependencies ──────────────────────────────────────────────\n",
        "!pip install torch torchvision pillow scikit-image tqdm\n",
        "\n",
        "# ─── 2. Download & Extract DIV2K ─────────────────────────────────────────\n",
        "import os\n",
        "if not os.path.isdir('DIV2K_train_HR'):\n",
        "    !wget -q https://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n",
        "    !unzip -q DIV2K_train_HR.zip\n",
        "    !rm DIV2K_train_HR.zip\n",
        "\n",
        "# ─── 3. Preprocess: Create LR Images ──────────────────────────────────────\n",
        "from PIL import Image\n",
        "def create_lr(hr_dir='DIV2K_train_HR', lr_dir='DIV2K_train_LR', scale=4):\n",
        "    os.makedirs(lr_dir, exist_ok=True)\n",
        "    for fn in os.listdir(hr_dir):\n",
        "        if not fn.lower().endswith(('png','jpg','jpeg')):\n",
        "            continue\n",
        "        hr = Image.open(f'{hr_dir}/{fn}').convert('RGB')\n",
        "        w, h = hr.size\n",
        "        lr = hr.resize((w//scale, h//scale), Image.BICUBIC)\n",
        "        lr = lr.resize((w, h), Image.BICUBIC)\n",
        "        lr.save(f'{lr_dir}/{fn}')\n",
        "create_lr()\n",
        "\n",
        "# ─── 4. Imports & Dataset ─────────────────────────────────────────────────\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DIV2KDataset(Dataset):\n",
        "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
        "        self.hr_dir, self.lr_dir = hr_dir, lr_dir\n",
        "        self.fns = [f for f in os.listdir(hr_dir) if f.lower().endswith(('png','jpg'))]\n",
        "        self.transform = transform or Compose([ToTensor(), Normalize((0.5,)*3,(0.5,)*3)])\n",
        "    def __len__(self):\n",
        "        return len(self.fns)\n",
        "    def __getitem__(self, i):\n",
        "        hr = Image.open(f'{self.hr_dir}/{self.fns[i]}').convert('RGB')\n",
        "        lr = Image.open(f'{self.lr_dir}/{self.fns[i]}').convert('RGB')\n",
        "        return self.transform(lr), self.transform(hr)\n",
        "\n",
        "# ─── 5. Model Definitions ─────────────────────────────────────────────────\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, c=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c, c, 3, 1, 1), nn.BatchNorm2d(c), nn.PReLU(),\n",
        "            nn.Conv2d(c, c, 3, 1, 1), nn.BatchNorm2d(c)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.net(x)\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    def __init__(self, c, scale=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c, c * scale * scale, 3, 1, 1),\n",
        "            nn.PixelShuffle(scale),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, num_res=16, up=4):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 9, 1, 4); self.pre1 = nn.PReLU()\n",
        "        self.res   = nn.Sequential(*[ResidualBlock(64) for _ in range(num_res)])\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, 1, 1); self.bn2 = nn.BatchNorm2d(64)\n",
        "        ups = []\n",
        "        for _ in range(up // 2):\n",
        "            ups.append(UpsampleBlock(64, 2))\n",
        "        self.ups = nn.Sequential(*ups)\n",
        "        self.conv3 = nn.Conv2d(64, 3, 9, 1, 4)\n",
        "    def forward(self, x):\n",
        "        out1 = self.pre1(self.conv1(x))\n",
        "        out  = self.res(out1)\n",
        "        out  = self.bn2(self.conv2(out)) + out1\n",
        "        out  = self.ups(out)\n",
        "        out  = self.conv3(out)\n",
        "        return (torch.tanh(out) + 1) / 2\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        def b(in_c, out_c, s):\n",
        "            layers.extend([nn.Conv2d(in_c, out_c, 3, s, 1), nn.BatchNorm2d(out_c), nn.LeakyReLU(0.2)])\n",
        "        b(3, 64, 1); b(64, 64, 2); b(64, 128, 1); b(128, 128, 2)\n",
        "        b(128, 256, 1); b(256, 256, 2); b(256, 512, 1); b(512, 512, 2)\n",
        "        layers += [\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 1)\n",
        "        ]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DenseResidualBlock(nn.Module):\n",
        "    def __init__(self, in_c, gr=32):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(5):\n",
        "            self.layers.append(nn.Sequential(\n",
        "                nn.Conv2d(in_c + i * gr, gr, 3, 1, 1),\n",
        "                nn.LeakyReLU(0.2)\n",
        "            ))\n",
        "        self.conv1x1 = nn.Conv2d(in_c + 5 * gr, in_c, 1, 1, 0)\n",
        "    def forward(self, x):\n",
        "        feats = [x]\n",
        "        for layer in self.layers:\n",
        "            out = layer(torch.cat(feats, 1)); feats.append(out)\n",
        "        out = torch.cat(feats, 1)\n",
        "        return x + 0.2 * self.conv1x1(out)\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, in_c=64):\n",
        "        super().__init__()\n",
        "        self.rdb1 = DenseResidualBlock(in_c)\n",
        "        self.rdb2 = DenseResidualBlock(in_c)\n",
        "        self.rdb3 = DenseResidualBlock(in_c)\n",
        "    def forward(self, x):\n",
        "        return x + 0.2 * self.rdb3(self.rdb2(self.rdb1(x)))\n",
        "\n",
        "class EnhancedGenerator(Generator):\n",
        "    def __init__(self, rrdb_blocks=23):\n",
        "        super().__init__(num_res=0, up=4)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 9, 1, 4); self.pre1 = nn.PReLU()\n",
        "        self.trunk = nn.Sequential(*[RRDB(64) for _ in range(rrdb_blocks)])\n",
        "        self.trunk_conv = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        ups = []\n",
        "        for _ in range(2):\n",
        "            ups += [nn.Conv2d(64, 256, 3, 1, 1), nn.PixelShuffle(2), nn.PReLU()]\n",
        "        self.ups = nn.Sequential(*ups)\n",
        "        self.conv_last = nn.Conv2d(64, 3, 9, 1, 4)\n",
        "    def forward(self, x):\n",
        "        out1 = self.pre1(self.conv1(x))\n",
        "        out  = self.trunk(out1)\n",
        "        out  = self.trunk_conv(out) + out1\n",
        "        out  = self.ups(out)\n",
        "        out  = self.conv_last(out)\n",
        "        return (torch.tanh(out) + 1) / 2\n",
        "\n",
        "# ─── 6. Training Functions (with epoch prints) ─────────────────────────────\n",
        "def train_srgan(hr_dir, lr_dir, epochs=30, bs=16, lr=1e-4, save_every=10):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ds = DIV2KDataset(hr_dir, lr_dir)\n",
        "    dl = DataLoader(ds, bs, shuffle=True, num_workers=4)\n",
        "    G, D = Generator().to(device), Discriminator().to(device)\n",
        "    optG = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.9,0.999))\n",
        "    optD = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.9,0.999))\n",
        "    mse = nn.MSELoss(); bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        G.train(); D.train()\n",
        "        for lr_imgs, hr_imgs in tqdm(dl, desc=f\"SRGAN Ep {e}/{epochs}\"):\n",
        "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "            valid = torch.ones(len(lr_imgs), 1, device=device)\n",
        "            fake  = torch.zeros(len(lr_imgs), 1, device=device)\n",
        "\n",
        "            # Discriminator step\n",
        "            gen_hr_detached = G(lr_imgs).detach()\n",
        "            lossD = (bce(D(hr_imgs), valid) + bce(D(gen_hr_detached), fake)) / 2\n",
        "            optD.zero_grad(); lossD.backward(); optD.step()\n",
        "\n",
        "            # Generator step\n",
        "            gen_hr = G(lr_imgs)\n",
        "            loss_content = mse(gen_hr, hr_imgs)\n",
        "            loss_adv     = bce(D(gen_hr), valid)\n",
        "            loss_pix     = mse(gen_hr, hr_imgs)\n",
        "            lossG        = loss_content + 1e-3 * loss_adv + 2e-6 * loss_pix\n",
        "            optG.zero_grad(); lossG.backward(); optG.step()\n",
        "\n",
        "        # Show epoch progress\n",
        "        print(f\"Completed epoch {e}/{epochs}\")\n",
        "\n",
        "        if e % save_every == 0:\n",
        "            torch.save(G.state_dict(), f'gen_{e}.pth')\n",
        "            torch.save(D.state_dict(), f'disc_{e}.pth')\n",
        "\n",
        "def train_enhanced(hr_dir, lr_dir, sr_ckpt=None, epochs=30, bs=16, lr=1e-4, save_every=10):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ds = DIV2KDataset(hr_dir, lr_dir)\n",
        "    dl = DataLoader(ds, bs, shuffle=True, num_workers=4)\n",
        "    G = EnhancedGenerator().to(device)\n",
        "    if sr_ckpt:\n",
        "        G.load_state_dict(torch.load(sr_ckpt))\n",
        "    D = Discriminator().to(device)\n",
        "    optG = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.9,0.999))\n",
        "    optD = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.9,0.999))\n",
        "    mse = nn.MSELoss(); bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        G.train(); D.train()\n",
        "        for lr_imgs, hr_imgs in tqdm(dl, desc=f\"Enh Ep {e}/{epochs}\"):\n",
        "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "            valid = torch.ones(len(lr_imgs), 1, device=device)\n",
        "            fake  = torch.zeros(len(lr_imgs), 1, device=device)\n",
        "\n",
        "            # Discriminator step\n",
        "            gen_hr_detached = G(lr_imgs).detach()\n",
        "            lossD = (bce(D(hr_imgs), valid) + bce(D(gen_hr_detached), fake)) / 2\n",
        "            optD.zero_grad(); lossD.backward(); optD.step()\n",
        "\n",
        "            # Generator step\n",
        "            gen_hr = G(lr_imgs)\n",
        "            loss_content = mse(gen_hr, hr_imgs)\n",
        "            loss_adv     = bce(D(gen_hr), valid)\n",
        "            loss_pix     = mse(gen_hr, hr_imgs)\n",
        "            lossG        = loss_content + 0.01 * loss_adv + 0.006 * loss_pix\n",
        "            optG.zero_grad(); lossG.backward(); optG.step()\n",
        "\n",
        "        # Show epoch progress\n",
        "        print(f\"Completed epoch {e}/{epochs}\")\n",
        "\n",
        "        if e % save_every == 0:\n",
        "            torch.save(G.state_dict(), f'enh_gen_{e}.pth')\n",
        "            torch.save(D.state_dict(), f'enh_disc_{e}.pth')\n",
        "\n",
        "# ─── 7. Evaluation ────────────────────────────────────────────────────────\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(ckpt, hr_dir, lr_dir, enhanced=False):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    G = EnhancedGenerator().to(device) if enhanced else Generator().to(device)\n",
        "    G.load_state_dict(torch.load(ckpt, map_location=device))\n",
        "    G.eval()\n",
        "    ds = DIV2KDataset(hr_dir, lr_dir)\n",
        "    ps, ss = [], []\n",
        "    for lr, hr in tqdm(DataLoader(ds,1), desc=\"Eval\"):\n",
        "        lr, hr = lr.to(device), hr.to(device)\n",
        "        with torch.no_grad():\n",
        "            out = G(lr)\n",
        "        out_np = ((out.squeeze().permute(1,2,0).cpu().numpy()*255)).astype(np.uint8)\n",
        "        hr_np  = ((hr.squeeze().permute(1,2,0).cpu().numpy()*255)).astype(np.uint8)\n",
        "        ps.append(psnr(hr_np, out_np, data_range=255))\n",
        "        ss.append(ssim(hr_np, out_np, multichannel=True, data_range=255))\n",
        "    print(f'Average PSNR: {np.mean(ps):.4f}, Average SSIM: {np.mean(ss):.4f}')\n",
        "\n",
        "# ─── 8. Run Training & Eval ───────────────────────────────────────────────\n",
        "# Example usage:\n",
        "train_srgan('DIV2K_train_HR','DIV2K_train_LR', epochs=30)\n",
        "train_enhanced('DIV2K_train_HR','DIV2K_train_LR','gen_200.pth', epochs=30)\n",
        "evaluate('enh_gen_100.pth','DIV2K_train_HR','DIV2K_train_LR', enhanced=True)"
      ]
    }
  ]
}